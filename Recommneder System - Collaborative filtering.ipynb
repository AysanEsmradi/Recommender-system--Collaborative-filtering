{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f6b926",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043c7d84",
   "metadata": {},
   "source": [
    "For the Questions 1-2, use the dataset MovieLens 100K.\n",
    "\n",
    "Hints:\n",
    "\n",
    "(1) The raw ids are ids that are defined in the rating file “u.data” in the MovieLens 100K\n",
    "dataset.\n",
    "\n",
    "(2) For movie names, refer to the file “u.item” in the MovieLens 100K dataset.\n",
    "\n",
    "(3) Use the whole dataset for similarity calculation.\n",
    "\n",
    "Dataset reference: https://grouplens.org/datasets/movielens/100k/\n",
    "\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec6378",
   "metadata": {},
   "source": [
    "### Question 1: about user-user similarity:\n",
    "\n",
    "Task: Find out 5 users who are most similar to the user with the raw id of 243, and show\n",
    "the raw ids of these 5 users. \n",
    "\n",
    "a. Compute user-user similarities by Pearson Correlation and obtain the result;\n",
    "\n",
    "b. Compute user-user similarities by Cosine Similarity and obtain the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce1e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import NormalPredictor\n",
    "from surprise import accuracy\n",
    "from surprise import KNNBaseline\n",
    "from surprise import Dataset\n",
    "from surprise import get_dataset_dir\n",
    "import io\n",
    "from scipy import spatial\n",
    "from scipy import stats\n",
    "import math\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af97f63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x1c3ec68fee0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the movielens-100k dataset\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "data.raw_ratings[:10] # first ten recoreds\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49cfe27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a) with pearson correlation\n",
    "# Retrieve the trainset (whole dataset)\n",
    "All_trainset = data.build_full_trainset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f28ad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1c3ec6b94f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, train the algortihm to compute the similarities between users\n",
    "sim_options = {'name': 'pearson',\n",
    "               'user_based': True,  # compute  similarities between users\n",
    "               }\n",
    "algo = KNNBasic(k=40,sim_options=sim_options) \n",
    "\n",
    "algo.fit(All_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394543fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['172', '191', '153', '103', '9']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similar_users_with_pearson(top_k,u_id):\n",
    "    \n",
    "    # Retrieve inner id\n",
    "    UserInnerId = algo.trainset.to_inner_uid(u_id)\n",
    "    \n",
    "    # Retrieve inner ids of the nearest neighbors usign the get_neighbors from surprise library\n",
    "    UserNeighbors = algo.get_neighbors( UserInnerId, k=top_k)\n",
    "    #Convert a user inner id to a raw id.\n",
    "    UserNeighbors = (algo.trainset.to_raw_uid(inner_id) for inner_id in UserNeighbors)\n",
    "\n",
    "    return UserNeighbors\n",
    "\n",
    "list(similar_users_with_pearson(5,'243'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9977064c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1c3ff6f82b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b) with cosine similarity\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True,  # compute  similarities between users\n",
    "               }\n",
    "algo = KNNBasic(k=40,sim_options=sim_options) \n",
    "\n",
    "algo.fit(All_trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dac0487f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['166', '127', '135', '229', '36']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def similar_users_with_cosine(top_k,u_id):\n",
    "    \n",
    "    UserInnerId = algo.trainset.to_inner_uid(u_id)\n",
    "    # Retrieve inner ids of the nearest neighbors usign the get_neighbors from surprise library\n",
    "    UserNeighbors = algo.get_neighbors(UserInnerId, k=top_k)\n",
    "    #Convert a user inner id to a raw id.\n",
    "    UserNeighbors = (algo.trainset.to_raw_uid(inner_id) for inner_id in UserNeighbors)\n",
    "\n",
    "    return UserNeighbors\n",
    "\n",
    "list(similar_users_with_cosine(5,'243'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5f8b69",
   "metadata": {},
   "source": [
    "### Question 2 about item-item similarity:\n",
    "\n",
    "Task: Find out 5 movies that are most similar to the Movie named “Toy Story” (movie id: 1), and show the raw ids and the names of these 5 movies.\n",
    "\n",
    "a. Compute item-item similarities by Pearson Correlation and obtain the result;\n",
    "\n",
    "b. Compute item-item similarities by (basic) Cosine Similarity and obtain the result;\n",
    "\n",
    "c. Compute item-item similarities by adjusted Cosine Similarity and obtain the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "328edf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_item_names():\n",
    "\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "\n",
    "    return rid_to_name, name_to_rid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abb7123",
   "metadata": {},
   "source": [
    "#### a) Pearson Correlaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "7657e9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# First, train the algortihm to compute the similarities between items\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {'name': 'pearson', 'user_based': False}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# Retrieve inner id of the movie Toy Story\n",
    "toy_story_raw_id = name_to_rid['Toy Story (1995)']\n",
    "toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n",
    "\n",
    "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=5)\n",
    "\n",
    "# Convert inner ids of the neighbors into names.\n",
    "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                       for inner_id in toy_story_neighbors)\n",
    "toy_story_neighbors = (rid_to_name[rid]\n",
    "                       for rid in toy_story_neighbors)\n",
    "\n",
    "List_neighbors = []\n",
    "for movie in toy_story_neighbors:\n",
    "    List_neighbors.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "cbe28da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "item_algo = KNNBasic(sim_options={'name': 'pearson','user_based': False}) \n",
    "\n",
    "item_algo.fit(trainset)\n",
    "\n",
    "def similar_items_with_pearson(top_k,item_id):\n",
    "\n",
    "    item_inner_id = item_algo.trainset.to_inner_iid(item_id)\n",
    "\n",
    "    item_neighbors = item_algo.get_neighbors(item_inner_id, k=top_k)\n",
    "\n",
    "    f_item_neighbors = (item_algo.trainset.to_raw_iid(inner_id)\n",
    "\n",
    "    for inner_id in item_neighbors)\n",
    "\n",
    "    return f_item_neighbors\n",
    "\n",
    "List_id=list(similar_items_with_pearson(5,'1'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "bcce8dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 nearest neighbors of Toy Story with Pearson Correlation are:\n",
      "\n",
      "1 ) ID: 1497 - Name of movie: Line King: Al Hirschfeld, The (1996)\n",
      "2 ) ID: 1186 - Name of movie: Inkwell, The (1994)\n",
      "3 ) ID: 1464 - Name of movie: Stars Fell on Henrietta, The (1995)\n",
      "4 ) ID: 341 - Name of movie: Critical Care (1997)\n",
      "5 ) ID: 1242 - Name of movie: Old Lady Who Walked in the Sea, The (Vieille qui marchait dans la mer, La) (1991)\n"
     ]
    }
   ],
   "source": [
    "print('The 5 nearest neighbors of Toy Story with Pearson Correlation are:')\n",
    "print()\n",
    "for i in range(5):\n",
    "    print(i+1,\") ID:\" ,List_id[i],\"- Name of movie:\",List_neighbors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ef56f",
   "metadata": {},
   "source": [
    "#### b) Cosine sililarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "8bc4a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# First, train the algortihm to compute the similarities between items\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset = data.build_full_trainset()\n",
    "sim_options = {'name': 'cosine', 'user_based': False}\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# Retrieve inner id of the movie Toy Story\n",
    "toy_story_raw_id = name_to_rid['Toy Story (1995)']\n",
    "toy_story_inner_id = algo.trainset.to_inner_iid(toy_story_raw_id)\n",
    "\n",
    "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "toy_story_neighbors = algo.get_neighbors(toy_story_inner_id, k=5)\n",
    "\n",
    "# Convert inner ids of the neighbors into names.\n",
    "toy_story_neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                       for inner_id in toy_story_neighbors)\n",
    "toy_story_neighbors = (rid_to_name[rid]\n",
    "                       for rid in toy_story_neighbors)\n",
    "\n",
    "List_neighbors = []\n",
    "for movie in toy_story_neighbors:\n",
    "    List_neighbors.append(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "815f5094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "item_algo = KNNBasic(sim_options={'name': 'cosine','user_based': False}) \n",
    "\n",
    "item_algo.fit(trainset)\n",
    "\n",
    "def similar_items_with_cosine(top_k,item_id):\n",
    "\n",
    "    item_inner_id = item_algo.trainset.to_inner_iid(item_id)\n",
    "\n",
    "    item_neighbors = item_algo.get_neighbors(item_inner_id, k=top_k)\n",
    "\n",
    "    f_item_neighbors = (item_algo.trainset.to_raw_iid(inner_id)\n",
    "\n",
    "    for inner_id in item_neighbors)\n",
    "\n",
    "    return f_item_neighbors\n",
    "\n",
    "List_iid=list(similar_items_with_cosine(5,'1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "0885b92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 5 nearest neighbors of Toy Story with Cosine Similarity are:\n",
      "\n",
      "1 ) ID: 626 - Name of movie: So Dear to My Heart (1949)\n",
      "2 ) ID: 1332 - Name of movie: My Life and Times With Antonin Artaud (En compagnie d'Antonin Artaud) (1993)\n",
      "3 ) ID: 1334 - Name of movie: Somebody to Love (1994)\n",
      "4 ) ID: 1350 - Name of movie: Crows and Sparrows (1949)\n",
      "5 ) ID: 1260 - Name of movie: Total Eclipse (1995)\n"
     ]
    }
   ],
   "source": [
    "print('The 5 nearest neighbors of Toy Story with Cosine Similarity are:')\n",
    "print()\n",
    "for i in range(5):\n",
    "    print(i+1,\") ID:\" ,List_iid[i],\"- Name of movie:\",List_neighbors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0b885",
   "metadata": {},
   "source": [
    "#### c) Adjusted Cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b838cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "2b7635eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movielens-100k dataset\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "train_set = data.build_full_trainset()\n",
    "#print(trainset.to_inner_uid('186')) # here one will print 1\n",
    "#print(trainset.to_raw_iid(1014))\n",
    "#trainset.ur[0][1][1]  for user number zero the 1 row, 1 data (that is item id)\n",
    "#trainset.ur[0] #it gives a list like this : uid: [(iid,rating)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "bf5392df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "1682\n"
     ]
    }
   ],
   "source": [
    "train_user_list = [u_id  for u_id in train_set.ur.keys()]\n",
    "print(len(train_user_list))\n",
    "\n",
    "train_item_list = [ i_id  for i_id in train_set.ir.keys()]\n",
    "print(len(train_item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "54050d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0         1         2         3         4         5         6     \\\n",
      "0  0.000000  0.459114  1.000000 -0.384484  0.616092  0.162003  0.120053   \n",
      "1  0.459114  0.000000 -0.715449 -0.102312  0.405081  0.622343  0.288585   \n",
      "2  1.000000 -0.715449  0.000000  0.174535 -1.000000 -0.909653 -0.321567   \n",
      "3 -0.384484 -0.102312  0.174535  0.000000 -0.240694 -0.148113  0.035582   \n",
      "4  0.616092  0.405081 -1.000000 -0.240694  0.000000  0.344501  0.118103   \n",
      "\n",
      "       7         8         9     ...      1672  1673  1674  1675  1676  1677  \\\n",
      "0 -0.416933  0.246056  0.447064  ...  0.847661   0.0   1.0   0.0   0.0   0.0   \n",
      "1 -0.109022  0.020597  0.171639  ...  0.728160   0.0   1.0  -1.0   0.0   0.0   \n",
      "2  0.549063  0.139658  0.401550  ...  0.000000   1.0   0.0   0.0   0.0   0.0   \n",
      "3 -0.251833 -0.245013 -0.239582  ...  0.728160   0.0  -1.0   0.0   1.0   0.0   \n",
      "4  0.434372 -0.341546  0.099995  ...  0.069474   0.0   1.0   0.0   0.0   0.0   \n",
      "\n",
      "   1678  1679  1680  1681  \n",
      "0   1.0   1.0   1.0   1.0  \n",
      "1   1.0   1.0   1.0   1.0  \n",
      "2   0.0   0.0   0.0   0.0  \n",
      "3  -1.0  -1.0  -1.0  -1.0  \n",
      "4   1.0   1.0   1.0   1.0  \n",
      "\n",
      "[5 rows x 1682 columns]\n"
     ]
    }
   ],
   "source": [
    "# calculate adjusted similarity between two items\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# initiate the matrix for storing the similarity values, (1682*1682)\n",
    "sim_item = np.empty((len(train_item_list),len(train_item_list)))\n",
    "\n",
    "# calculateing the mean rating of each user\n",
    "u_rating_mean= {}\n",
    "for u_id in range(len(train_user_list)):\n",
    "    sum_r = 0\n",
    "    count = 0\n",
    "    for (i,r) in train_set.ur[u_id]:\n",
    "        sum_r += r\n",
    "        count += 1\n",
    "    u_rating_mean[u_id] = sum_r / count # for each user,this dict retuens its mean rating\n",
    "    \n",
    "# loop through all items to calculate the similaity\n",
    "for i1_id in range(len(train_item_list)):\n",
    "    for i2_id in range(i1_id+1,len(train_item_list)):\n",
    "        \n",
    "        # A: find common users that rated to both i1 and i2\n",
    "        i1_user_rating_dict = {}     \n",
    "        for (i, r) in train_set.ir[i1_id]:\n",
    "            i1_user_rating_dict[i] = r\n",
    "        i2_user_rating_dict = {}\n",
    "        for (i, r) in train_set.ir[i2_id]:\n",
    "            i2_user_rating_dict[i] = r\n",
    "        common_users = list(set.intersection(set(i1_user_rating_dict.keys()), \\\n",
    "                                             set(i2_user_rating_dict.keys())))\n",
    "        \n",
    "        \n",
    "        # B: construct rating vectors of common users for two items\n",
    "        i1_rating_list = []\n",
    "        i2_rating_list = []\n",
    "        commonuser_rating_mean = []   # I have created an empty list to access the average ranking of common users\n",
    "        for i in common_users:\n",
    "            i1_rating_list.append(i1_user_rating_dict[i]) \n",
    "            i2_rating_list.append(i2_user_rating_dict[i]) \n",
    "            commonuser_rating_mean.append(u_rating_mean[i])\n",
    "            \n",
    "        dif_i1_and_mean = []\n",
    "        for i in range(len(i1_rating_list)):\n",
    "            d = i1_rating_list[i] - commonuser_rating_mean[i]\n",
    "            dif_i1_and_mean.append(d)\n",
    "  \n",
    "        dif_i2_and_mean = []\n",
    "        for i in range(len(i2_rating_list)):\n",
    "            d2 = i2_rating_list[i] - commonuser_rating_mean[i]\n",
    "            dif_i2_and_mean.append(d2)\n",
    "    \n",
    "        # C: calculate the similarities between two items \n",
    "        # - we used adjusted cosine similairty here\n",
    "        \n",
    "        if len(common_users) > 0:\n",
    "            adjcos_sim = 1 - spatial.distance.cosine( dif_i1_and_mean , dif_i2_and_mean)\n",
    "        else: \n",
    "            adjcos_sim = 0\n",
    "            \n",
    "    \n",
    "        # D: store measured similarity into matrix\n",
    "        sim_item[i1_id][i2_id] = adjcos_sim\n",
    "        sim_item[i2_id][i1_id] = adjcos_sim\n",
    "\n",
    "        \n",
    "#After completing the calculation, store the similarity matrix into a table\n",
    "sim_matrix_table = pd.DataFrame(sim_item)\n",
    "print(sim_matrix_table.head(5))\n",
    "sim_matrix_table.to_csv('item_similarty_table.csv') \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "5c40b1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "[(756, 1.0), (941, 1.0), (962, 1.0), (1033, 1.0), (1038, 1.0)]\n",
      "With row item id we have: ['1436', '1493', '1464', '830', '1189']\n"
     ]
    }
   ],
   "source": [
    "raw_item_id = str(1)\n",
    "k = 5\n",
    "\n",
    "item_id = train_set.to_inner_iid(raw_item_id)\n",
    "print(item_id)\n",
    "\n",
    "neighbors = []\n",
    "neighbors_sim_dict = {}\n",
    "for u in train_item_list:\n",
    "    if item_id != u:\n",
    "        neighbors.append(u)\n",
    "        neighbors_sim_dict[u] = sim_item[item_id, u]\n",
    "    \n",
    "\n",
    "# get K nearest neighbors\n",
    "k_neighbors = sorted(neighbors_sim_dict.items(), reverse=True, key=lambda item: item[1])[:k]\n",
    "print(k_neighbors)\n",
    "\n",
    "List_row= [ ]\n",
    "for (i,r) in k_neighbors:\n",
    "    List_row.append(train_set.to_raw_iid(i))\n",
    "\n",
    "print(\"With row item id we have:\",List_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "0bb4eac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1436', '1493', '1464', '830', '1189']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "d42f111b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Jones (1993)\n",
      "Modern Affair, A (1995)\n",
      "Stars Fell on Henrietta, The (1995)\n",
      "Power 98 (1995)\n",
      "Prefontaine (1997)\n"
     ]
    }
   ],
   "source": [
    "toy_story_neighbors = (rid_to_name[rid]\n",
    "                       for rid in List_row)\n",
    "\n",
    "for movie in toy_story_neighbors:\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1ef1de",
   "metadata": {},
   "source": [
    "### Question 3 :\n",
    "Task: Conduct a comparison between centered user-based k-NN (with means) and\n",
    "centered item-based k-NN (with means) on the Jester dataset (see the attached dataset\n",
    "Jester_200.zip). Note that you need to load the data file jester_ratings_200.dat first by\n",
    "using ‘Dataset.load_from_file()’ in Surprise.\n",
    "\n",
    "a. Use Grid Search to search for the best combination of similarity measure and k value\n",
    "for each method (metric is RMSE);\n",
    "\n",
    "b. Use the 10-fold cross-validation to test the best combination for each method;\n",
    "\n",
    "c. Compare the two methods’ results through Two-Sample t-Test;\n",
    "\n",
    "d. Briefly describe the results and discuss the two methods’ performance on this dataset.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0970be9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('162', '5', 3.719, None),\n",
       " ('162', '7', 9.75, None),\n",
       " ('162', '8', 7.469, None),\n",
       " ('162', '13', -9.812, None),\n",
       " ('162', '15', 2.312, None),\n",
       " ('162', '16', 5.031, None),\n",
       " ('162', '17', 0.469, None),\n",
       " ('162', '18', -2.594, None),\n",
       " ('162', '19', 5.531, None),\n",
       " ('162', '20', -1.688, None)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import KNNWithMeans\n",
    "from surprise.model_selection import GridSearchCV\n",
    "from surprise.model_selection import cross_validate\n",
    "import os\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# path to dataset file\n",
    "file_path = os.path.expanduser('./jester_ratings_200.dat')\n",
    "reader = Reader(line_format='user item rating', sep='\\t\\t')\n",
    "data = Dataset.load_from_file(file_path, reader=reader)\n",
    "data.raw_ratings[:10] # first ten recoreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4b09e2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNWithMeans on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    4.3353  4.5411  4.3793  4.4930  4.3335  4.5602  4.3952  4.4705  4.4062  4.4593  4.4374  0.0761  \n",
      "Fit time          0.09    0.12    0.12    0.10    0.11    0.13    0.13    0.13    0.13    0.14    0.12    0.01    \n",
      "Test time         0.14    0.12    0.17    0.15    0.17    0.18    0.20    0.17    0.18    0.18    0.17    0.02    \n"
     ]
    }
   ],
   "source": [
    "# a,b) \n",
    "gs_cv = 3\n",
    "eval_cv = 10\n",
    "\n",
    "# Use Centered KNN (user-based) algorithms\n",
    "user_based_param_grid = {'k': [10, 20, 60, 90, 125, 200],\n",
    "              'sim_options':{\n",
    "                  'name': ['cosine','pearson'],\n",
    "                  'user_based': [True]\n",
    "                  }\n",
    "             }\n",
    "\n",
    "# Find out the best combination of similarity measurement and k value \n",
    "user_based_gs = GridSearchCV(KNNWithMeans, user_based_param_grid, measures=['rmse'], cv=gs_cv)\n",
    "user_based_gs.fit(data)\n",
    "user_based_algo = user_based_gs.best_estimator['rmse']\n",
    "\n",
    "# Use cross validation to evaluate the best model\n",
    "user_best_result = cross_validate(user_based_algo, data, measures=['rmse'], cv=eval_cv, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "362233eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE of algorithm KNNWithMeans on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    4.4707  4.3386  4.5120  4.3953  4.4067  4.4842  4.4212  4.3252  4.3690  4.3943  4.4117  0.0584  \n",
      "Fit time          0.07    0.08    0.08    0.09    0.08    0.08    0.07    0.09    0.06    0.08    0.08    0.01    \n",
      "Test time         0.08    0.08    0.09    0.12    0.09    0.08    0.08    0.08    0.10    0.11    0.09    0.01    \n"
     ]
    }
   ],
   "source": [
    "# Use Centered KNN (item-based) algorithms\n",
    "\n",
    "# Find out the best combination of similarity measurement and k value \n",
    "item_based_param_grid = {'k': [10, 20, 60, 90, 125, 200],\n",
    "              'sim_options':{\n",
    "                  'name': ['cosine','pearson'],\n",
    "                  'user_based': [False]\n",
    "                  }\n",
    "             }\n",
    "item_based_gs = GridSearchCV(KNNWithMeans, item_based_param_grid, measures=['rmse'], cv=gs_cv)\n",
    "item_based_gs.fit(data)\n",
    "\n",
    "item_based_algo = item_based_gs.best_estimator['rmse']\n",
    "\n",
    "# Use cross validation to evaluate the best model\n",
    "item_best_result = cross_validate(item_based_algo, data, measures=['rmse'], cv=eval_cv,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a932e8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 60, 'sim_options': {'name': 'pearson', 'user_based': True}}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_based_gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e36d3a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k': 20, 'sim_options': {'name': 'cosine', 'user_based': False}}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_based_gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "72171ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.33534511 4.54114223 4.37929032 4.49299361 4.3335028  4.56022417\n",
      " 4.39520036 4.47050553 4.40618164 4.45927413]\n",
      "[4.47070944 4.33863671 4.51196758 4.3952563  4.40670497 4.48424168\n",
      " 4.42120875 4.32521619 4.36903056 4.39429541]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.8020081775944554, pvalue=0.43300956897443577)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c) T-Test\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "user_based_RMSE = user_best_result['test_rmse']\n",
    "item_based_RMSE = item_best_result['test_rmse']\n",
    "\n",
    "print(user_based_RMSE)\n",
    "print(item_based_RMSE)\n",
    "\n",
    "ttest_ind(user_based_RMSE,item_based_RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0cd252",
   "metadata": {},
   "source": [
    "d)\n",
    "\n",
    "If  𝑝  <0.05, it means significant difference between two methods.\n",
    "\n",
    "Conclusion:\n",
    "\n",
    "For Jester_200, the result showed that there is no significant difference between item-based centered k-NN and user_based centered k-NN.\n",
    "\n",
    "The mean of user_based centered k-NN is 4.4374 and the mean of item-based centered k-NN is 4.4117 which are close to each other and it was confirmed by T-test that these differences are not significant. \n",
    "\n",
    "We also showed that the best parameter combination for the user_based centered k-NN is to use k =60 and pearson correlation as measurment similarity, and the best parameter combination for the item_based centered k-NN is to use k =20 and cosine similarity as measurment similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e686c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
